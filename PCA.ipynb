{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import relevant libraries \n",
    "import string\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from itertools import tee, islice\n",
    "from sklearn.decomposition import PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize these words in a 2D space \n",
    "# (spanned by 1st and 2nd principal components) \n",
    "# via PCA\n",
    "# where PCA is applied to bi-gram word-context \n",
    "# matrix from Ulysses [see below]\n",
    "query_words = ['run','walk','shout','talk','speak','animal','duck','chicken','love','hate'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ulysses.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d8eb1be7b2d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load input text file for analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# (Ulysses by James Joyce, 1922)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ulysses.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Remove punctuations in text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ulysses.txt'"
     ]
    }
   ],
   "source": [
    "# Load input text file for analysis \n",
    "# (Ulysses by James Joyce, 1922)\n",
    "txt = open(\"ulysses.txt\",\"r\")\n",
    "\n",
    "# Remove punctuations in text\n",
    "remove = dict.fromkeys(map(ord, string.punctuation))\n",
    "\n",
    "# Collapse tokens to lower case\n",
    "txt = txt.read().translate(remove).lower()\n",
    "\n",
    "# Code for obtaining ngram counts with inputs \n",
    "# of \"lst\" = a list and \"n\" = n-gram order, \n",
    "# e.g. n=2 -> digram counts\n",
    "def ngrams(lst, n):\n",
    "    tlst = lst\n",
    "    while True:\n",
    "        a, b = tee(tlst)\n",
    "        l = tuple(islice(a, n))\n",
    "        if len(l) == n:\n",
    "            yield l\n",
    "            next(b)\n",
    "            tlst = b\n",
    "        else:\n",
    "            break\n",
    "\n",
    "# Split text into separate words\n",
    "txt_split = txt.split();\n",
    "def getUniqueWords(allWords) :\n",
    "    uniqueWords = [] \n",
    "    for i in allWords:\n",
    "        if not i in uniqueWords:\n",
    "            uniqueWords.append(i)\n",
    "    return uniqueWords\n",
    "unique = getUniqueWords(txt_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-5-2ae43f31b344>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-2ae43f31b344>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    n = a[(q, w)]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# Analysis begins here:\n",
    "a = collections.Counter(ngrams(txt_split, 2))\n",
    "com = []\n",
    "c = []\n",
    "for q in query_words:\n",
    "    for w in unique:\n",
    "  \n",
    "    n = a[(q, w)]\n",
    "    c.append(n)\n",
    "    com.append((q,w))\n",
    "\n",
    "a = c[:30527]\n",
    "b = c[30527:30527*2]\n",
    "c_1 = c[30527*2:30527*3]\n",
    "d = c[30527*3:30527*4]\n",
    "e = c[30527*4:30527*5]\n",
    "f = c[30527*5:30527*6]\n",
    "g = c[30527*6:30527*7]\n",
    "h = c[30527*7:30527*8]\n",
    "i = c[30527*8:30527*9]\n",
    "j = c[30527*9:30527*10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Construct a word-by-context matrix C where: \n",
    "# word (rows) = query_words provided\n",
    "# context (columns) = all unique words in txt_split\n",
    "# C[i,j] = Number of times that word i appears before context j in txt_split\n",
    "matrix_c = np.array([a, b, c_1, d, e, f, g, h, i, j])\n",
    "print (type(matrix_c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 2: Apply PCA to C\n",
    "pca = PCA(n_components = 2)\n",
    "pca.fit(matrix_c)\n",
    "#print (pca)\n",
    "first_pc = pca.components_[0]\n",
    "second_pc = pca.components_[1]\n",
    "transformed_data = pca.transform(matrix_c)\n",
    "# print (first_pc)\n",
    "# print (second_pc)\n",
    "# print (transformed_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 3: Visualize-print query words in the \n",
    "# first and second principal components space\n",
    "# Include your figure in writeup [1pt]\n",
    "\n",
    "plt.scatter(transformed_data[:,0], transformed_data[:,1])\n",
    "for i, col in enumerate(query_words):\n",
    "    plt.annotate(col, (transformed_data[:,0][i],transformed_data[:,1][i]), size = 4)\n",
    "\n",
    "#xticks = np.arange(-10, 20, 2)                                              \n",
    "#yticks = np.arange(-6, 12, 0.5)                                             \n",
    "#plt.xticks(xticks)\n",
    "#plt.yticks(yticks)\n",
    "plt.xlabel(\"PCA-1\")\n",
    "plt.ylabel(\"PCA-2\")                                                                                  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
